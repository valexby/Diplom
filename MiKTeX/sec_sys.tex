\section{СИСТЕМНОЕ ПРОЕКТИРОВАНИЕ}\label{sec:sys}
Изучив теоретические аспектыn разрабатываемого приложения и выработав список требований необходимых для разработки модуля, разбиваем систему на компоненты.
В разрабатываемом приложении можно выделить следующие блоки:
\begin{itemize}
\item модуль сбора статистики;
\item модуль объектно-реляционного отображения;
\item база данных объектов для анализа;
\item модуль развертки;
\item тренировочный набор Стенфорда;
\item модуль выделения особенностей;
\item модуль модели анализатора;
\item модуль ячейки Tree LSTM\@;
\item визуализации CoreNLP\@;
\item модуль визуализации TensorBoard.
\end{itemize}
Структурная схема, иллюстрирующая перечисленные блоки и связи между ними приведена на чертеже ГУИР.400201.009 C1.

Чтобы начать работу модели распознования тональностей, необходимы входные данные. Первый тип входных данных --- это тренировочный набор Стенфорда. Он необходим для обучения модели распознованию тональностей. Стенфордский набор Представляет собой выборку синтаксических деревьев составляющих. Однако модель должна работать с синтаксическими деревьями зависимостей. Поэтому необходимо привести его к виду синтаксических деревьев зависимостей. Так как исследование синтаксического разбора не входит в задачи проектирования, то для этой цели будет использоваться синтаксический анализатор из CoreNLP\@. Он не является самым производительным, но самым простым в применении. За несколько секунд он обрабатывает более 10000 предложений, составляющих Стенфордский тренировочный набор. Обработать тренировочный набор необходимо всего один, при устаfновке программы, поэтому скорость в несколько секунд вполне удовлетворительна. Объем анализатора вместе с моделью нейросети, обученной синтаксическому разбору, составляет более 350 мегабайт. Далее нужен предобученный набор встроенных векторов GloVe\@. Он содержит в себе 5 гигабайт слов и соответствующих им векторам размерностью в 300 состовляющих каждый. Чтобы сократить размер, занимаемый набором GloVe\@, он будет отфильтрован: будут выброшены все слова, которые не встречаются в Стенфордском тренировачном наборе. После такой фильтрации набор встраиваемых векторов будет занимать около 30 мегабайт дискового пространства. Фильтрацию так же необходимо произвести только один раз при установке программы. То есть, если перед началом работы программы произвести предобработку входных данных, то это повысит производительность и сократить объем, занимаемый системой на диске. Итак, чтобы решать проблему управления зависимостями, введен модуль развертки. В его задачи входит:

\begin{itemize}
\item проверить наличие отфильтрованного набора GloVe;
\item проверить наличие Стенфорского тренировочного набора в виде синтаксических деревьев зависимости;
\item проверить наличие синтаксического анализатора и скачать его, если отсутствует;
\item при необходимости скачать оригинальные набор GloVe и тренировочный набор;
\item при необходимости отфильтровать GloVe и удалить оригинальную версию;
\item при необходимости обработать оригинальный Стенфордский тренировочный набор с помощью синтаксического анализатора;
\item проверить наличиек необходимых библиотек и установить отсутствующие.
\end{itemize}

В результате работы модуля развертки, модель будет способна обучаться. Для того чтобы расширить возможности исследования возможностей модели, введен модуль сбора статистики. Его задачей будет сбор данных с сайта rottentomatoes.com, популярного форума о кино. Там собрано множество отзывов о фильмах последних десятилетий. Так же он предоставляет API для разработчиков, что поможет в сборе данных с ресурса. Для демонстрации хватит отзывов профессиональных критиков и обычных пользователей, и рейтинга фильма. Собранные через API данные необходимо хранить в базе данных, так как сбор данных для анализа может занять значительно больше времени, чем сам анализ. А база данных поможет сохранить результаты, и продолжить сбор информации в любое удобное время.

Так как сбор данных через API --- задача достаточно тривиальная, в которой производительность зависит от скорости обмена данными с сервером, то производительность языка Python даст удовлетворительные результаты. Так же Python скриптовый язык, что упростит разработку. Для работы с REST API отлично подойдет библиотека requests для Python, которая просто представяет собой реализацию REST-интерфеса и довольно проста в использовании.

В качестве базы данных будет использована Mysql, как стабильное и надежное решение. Для удобства работа с базой данных будет организована по принципу объектно-реляционного отображения. Данный принцип предполагает абстракцию модели транзакций и предлагает программную модель --- объекты базы данных представляются в виде объектов в модели объектно-ориентированного программирования. Для реализации объектно-реляционного отображения будет использована библиотека sqlalchemy, которая позволяет используя возможности языка Python максимально абстрагироваться от SQL\@. В объектах sqlalchemy будут хранится данные из базы данных. И любые изменения этих объектов sqlalchemy представляет в виде транзакции в базу, таким образом поддерживая актуальность данных в базе и в памяти программы.

Таким образом сбор данных для NLP-модели будет осуществлятся модулем сбора статистики через API ресурса rottentomatoes.com. Полученные от сайта объекты REST будут сохраняться в объектах Python, которые в свою очередь, являясь объекто-реляционным отображениями базы данных, будут управлять данными в базе. И затем, когда данные из базы данных потребуется проанализировать, то они будут загруженны в виде Python-объектов в рамках той же объектно-реляционной модели.